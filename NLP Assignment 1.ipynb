{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "00401906-b24e-494f-beca-f2a73e96daa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd # to work with csv files\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl \n",
    "import matplotlib.cm as cm \n",
    "import matplotlib.pyplot as plt \n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "31487729-c333-49b1-8604-e60d8866bba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import feature extraction methods from sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# pre-processing of text\n",
    "import string\n",
    "import re\n",
    "\n",
    "\n",
    "# import classifiers from sklearn\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "\n",
    "# import different metrics to evaluate the classifiers\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn import metrics\n",
    "\n",
    "# import time function from time module to track the training duration\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "539bfde5-8c50-4c69-a274-4916a7dded03",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('C://Users/dell/Downloads/Full-Economic-News-DFE-839861.csv', encoding = 'ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fcc1f9fd-185d-40f5-8f2c-748e3293211c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_unit_id</th>\n",
       "      <th>_golden</th>\n",
       "      <th>_unit_state</th>\n",
       "      <th>_trusted_judgments</th>\n",
       "      <th>_last_judgment_at</th>\n",
       "      <th>positivity</th>\n",
       "      <th>positivity:confidence</th>\n",
       "      <th>relevance</th>\n",
       "      <th>relevance:confidence</th>\n",
       "      <th>articleid</th>\n",
       "      <th>date</th>\n",
       "      <th>headline</th>\n",
       "      <th>positivity_gold</th>\n",
       "      <th>relevance_gold</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842613455</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>12/5/15 17:48</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.6400</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.640</td>\n",
       "      <td>wsj_398217788</td>\n",
       "      <td>8/14/91</td>\n",
       "      <td>Yields on CDs Fell in the Latest Week</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NEW YORK -- Yields on most certificates of dep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842613456</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>12/5/15 16:54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>1.000</td>\n",
       "      <td>wsj_399019502</td>\n",
       "      <td>8/21/07</td>\n",
       "      <td>The Morning Brief: White House Seeks to Limit ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Wall Street Journal Online&lt;/br&gt;&lt;/br&gt;The Mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>842613457</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>12/5/15 1:59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>1.000</td>\n",
       "      <td>wsj_398284048</td>\n",
       "      <td>11/14/91</td>\n",
       "      <td>Banking Bill Negotiators Set Compromise --- Pl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WASHINGTON -- In an effort to achieve banking ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>842613458</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>12/5/15 2:19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>no</td>\n",
       "      <td>0.675</td>\n",
       "      <td>wsj_397959018</td>\n",
       "      <td>6/16/86</td>\n",
       "      <td>Manager's Journal: Sniffing Out Drug Abusers I...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The statistics on the enormous costs of employ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>842613459</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>12/5/15 17:48</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.3257</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.640</td>\n",
       "      <td>wsj_398838054</td>\n",
       "      <td>10/4/02</td>\n",
       "      <td>Currency Trading: Dollar Remains in Tight Rang...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NEW YORK -- Indecision marked the dollar's ton...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    _unit_id  _golden _unit_state  _trusted_judgments _last_judgment_at  \\\n",
       "0  842613455    False   finalized                   3     12/5/15 17:48   \n",
       "1  842613456    False   finalized                   3     12/5/15 16:54   \n",
       "2  842613457    False   finalized                   3      12/5/15 1:59   \n",
       "3  842613458    False   finalized                   3      12/5/15 2:19   \n",
       "4  842613459    False   finalized                   3     12/5/15 17:48   \n",
       "\n",
       "   positivity  positivity:confidence relevance  relevance:confidence  \\\n",
       "0         3.0                 0.6400       yes                 0.640   \n",
       "1         NaN                    NaN        no                 1.000   \n",
       "2         NaN                    NaN        no                 1.000   \n",
       "3         NaN                 0.0000        no                 0.675   \n",
       "4         3.0                 0.3257       yes                 0.640   \n",
       "\n",
       "       articleid      date                                           headline  \\\n",
       "0  wsj_398217788   8/14/91              Yields on CDs Fell in the Latest Week   \n",
       "1  wsj_399019502   8/21/07  The Morning Brief: White House Seeks to Limit ...   \n",
       "2  wsj_398284048  11/14/91  Banking Bill Negotiators Set Compromise --- Pl...   \n",
       "3  wsj_397959018   6/16/86  Manager's Journal: Sniffing Out Drug Abusers I...   \n",
       "4  wsj_398838054   10/4/02  Currency Trading: Dollar Remains in Tight Rang...   \n",
       "\n",
       "   positivity_gold  relevance_gold  \\\n",
       "0              NaN             NaN   \n",
       "1              NaN             NaN   \n",
       "2              NaN             NaN   \n",
       "3              NaN             NaN   \n",
       "4              NaN             NaN   \n",
       "\n",
       "                                                text  \n",
       "0  NEW YORK -- Yields on most certificates of dep...  \n",
       "1  The Wall Street Journal Online</br></br>The Mo...  \n",
       "2  WASHINGTON -- In an effort to achieve banking ...  \n",
       "3  The statistics on the enormous costs of employ...  \n",
       "4  NEW YORK -- Indecision marked the dollar's ton...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94429b96-66b4-4758-a3c8-7d3ab7ab1380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_unit_id</th>\n",
       "      <th>_trusted_judgments</th>\n",
       "      <th>positivity</th>\n",
       "      <th>positivity:confidence</th>\n",
       "      <th>relevance:confidence</th>\n",
       "      <th>positivity_gold</th>\n",
       "      <th>relevance_gold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8.000000e+03</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>1420.000000</td>\n",
       "      <td>3775.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.367995e+08</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.985211</td>\n",
       "      <td>0.188450</td>\n",
       "      <td>0.859009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.816278e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.680357</td>\n",
       "      <td>0.269593</td>\n",
       "      <td>0.166180</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8.309816e+08</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.336400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.309836e+08</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.669700</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8.367995e+08</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.426155e+08</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.345800</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.426175e+08</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           _unit_id  _trusted_judgments   positivity  positivity:confidence  \\\n",
       "count  8.000000e+03              8000.0  1420.000000            3775.000000   \n",
       "mean   8.367995e+08                 3.0     4.985211               0.188450   \n",
       "std    5.816278e+06                 0.0     1.680357               0.269593   \n",
       "min    8.309816e+08                 3.0     2.000000               0.000000   \n",
       "25%    8.309836e+08                 3.0     3.000000               0.000000   \n",
       "50%    8.367995e+08                 3.0     5.000000               0.000000   \n",
       "75%    8.426155e+08                 3.0     7.000000               0.345800   \n",
       "max    8.426175e+08                 3.0     9.000000               1.000000   \n",
       "\n",
       "       relevance:confidence  positivity_gold  relevance_gold  \n",
       "count           8000.000000              0.0             0.0  \n",
       "mean               0.859009              NaN             NaN  \n",
       "std                0.166180              NaN             NaN  \n",
       "min                0.336400              NaN             NaN  \n",
       "25%                0.669700              NaN             NaN  \n",
       "50%                1.000000              NaN             NaN  \n",
       "75%                1.000000              NaN             NaN  \n",
       "max                1.000000              NaN             NaN  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "02164226-ddb4-4972-91f0-6e8445511721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8000 entries, 0 to 7999\n",
      "Data columns (total 15 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   _unit_id               8000 non-null   int64  \n",
      " 1   _golden                8000 non-null   bool   \n",
      " 2   _unit_state            8000 non-null   object \n",
      " 3   _trusted_judgments     8000 non-null   int64  \n",
      " 4   _last_judgment_at      8000 non-null   object \n",
      " 5   positivity             1420 non-null   float64\n",
      " 6   positivity:confidence  3775 non-null   float64\n",
      " 7   relevance              8000 non-null   object \n",
      " 8   relevance:confidence   8000 non-null   float64\n",
      " 9   articleid              8000 non-null   object \n",
      " 10  date                   8000 non-null   object \n",
      " 11  headline               8000 non-null   object \n",
      " 12  positivity_gold        0 non-null      float64\n",
      " 13  relevance_gold         0 non-null      float64\n",
      " 14  text                   8000 non-null   object \n",
      "dtypes: bool(1), float64(5), int64(2), object(7)\n",
      "memory usage: 882.9+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "229b83af-e67a-4287-8e47-3f7444a4c891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_unit_id                    0\n",
       "_golden                     0\n",
       "_unit_state                 0\n",
       "_trusted_judgments          0\n",
       "_last_judgment_at           0\n",
       "positivity               6580\n",
       "positivity:confidence    4225\n",
       "relevance                   0\n",
       "relevance:confidence        0\n",
       "articleid                   0\n",
       "date                        0\n",
       "headline                    0\n",
       "positivity_gold          8000\n",
       "relevance_gold           8000\n",
       "text                        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c090d84c-abaa-42a4-81a4-ad539fdcb4a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "relevance\n",
       "no          0.821375\n",
       "yes         0.177500\n",
       "not sure    0.001125\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"relevance\"].value_counts()/data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e648fc-12ba-4588-9e5c-e747c16a0297",
   "metadata": {},
   "source": [
    "##### There is an imbalance in the data with not relevant being 82% in the dataset. convert the class labels into binary outcome variables for convenience. 1 for Yes (relevant), and 0 for No (not relevant), and ignore \"Not sure\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "01fe0ea1-a83d-41f0-adfe-9f6f17035491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7991, 15)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert label to a numerical variable\n",
    "data = data[data.relevance != \"not sure\"] # removing the data where we don't want relevance=\"not sure\".\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c092ecb6-d0a2-4681-8635-8b842e7a3424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7991, 2)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['relevance'] = data.relevance.map({'yes':1, 'no':0}) # relevant is 1, not-relevant is 0. \n",
    "data = data[[\"text\",\"relevance\"]] # Let us take only the two columns we need.\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9b6511-ca42-4cf2-92c1-97c60106b195",
   "metadata": {},
   "source": [
    "## Section 2: Text Pre-processing\n",
    "- Typical steps involve tokenization, lower casing, removing, stop words, punctuation markers etc, and vectorization. Other processes such as stemming/lemmatization can also be performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b57fe09c-f019-4fd3-bfb8-8fd64e4e0dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(doc): # doc is a string of text\n",
    "    doc = doc.replace(\"</br>\", \" \")\n",
    "    doc = \"\".join([char for char in doc if char not in string.punctuation and not char.isdigit()])\n",
    "    doc = \" \".join([token for token in doc.split() if token not in stop_words])\n",
    "    # remove punctuation and numbers\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b428348e-89bd-4c97-9129-b4f466be832b",
   "metadata": {},
   "source": [
    "# Section 3: Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cd3977e9-920a-4e6d-b801-b8e535f804c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7991,) (7991,)\n",
      "(5993,) (5993,)\n",
      "(1998,) (1998,)\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Step 1: train-test split\n",
    "X = data.text # the column text contains textual data to extract features from\n",
    "y = data.relevance # this is the column we are learning to predict. \n",
    "print(X.shape, y.shape)\n",
    "# split X and y into training and testing sets. By default, it splits 75% training and 25% test\n",
    "# random_state=1 for reproducibility\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bb94617b-aa8d-47a8-9ce5-67ea994d6ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5993, 49869) (1998, 49869)\n"
     ]
    }
   ],
   "source": [
    "# Step 2-3: Preprocess and Vectorize train and test data\n",
    "vect = CountVectorizer(preprocessor=clean) # instantiate a vectoriezer\n",
    "X_train_dtm = vect.fit_transform(X_train)# use it to extract features from training data\n",
    "# transform testing data (using training data's features)\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "print(X_train_dtm.shape, X_test_dtm.shape)\n",
    "# i.e., the dimension of our feature vector is 49753!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "63fcd3e3-efdd-4ca1-9dc6-d8650fb239dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 15.6 ms\n",
      "Wall time: 38.4 ms\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Train the classifier and predict for test data\n",
    "nb = MultinomialNB() # instantiate a Multinomial Naive Bayes model\n",
    "%time nb.fit(X_train_dtm, y_train) # train the model(timing it with an IPython \"magic command\")\n",
    "y_pred_class = nb.predict(X_test_dtm) # make class predictions for X_test_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "22a77b48-755c-4b4d-9e0f-4fa5a5c9e350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7642642642642643\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'roc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[63], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# calculate evaluation measures:\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;124m\"\u001b[39m, accuracy_score(y_test, y_pred_class))\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAUC: \u001b[39m\u001b[38;5;124m\"\u001b[39m, roc(y_test, y_pred_prob))\n\u001b[0;32m     12\u001b[0m cnf_matrix \u001b[38;5;241m=\u001b[39m confusion_matrix(y_test, y_pred_class)\n\u001b[0;32m     13\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m6\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'roc' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression # import\n",
    "\n",
    "logreg = LogisticRegression(class_weight=\"balanced\") # instantiate a logistic regression model\n",
    "logreg.fit(X_train_dtm, y_train) # fit the model with training data\n",
    "\n",
    "# Make predictions on test data\n",
    "y_pred_class = logreg.predict(X_test_dtm)\n",
    "\n",
    "# calculate evaluation measures:\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred_class))\n",
    "print(\"AUC: \", roc(y_test, y_pred_prob))\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred_class)\n",
    "plt.figure(figsize=(8,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae4727b-dc0e-4404-97ff-6e86354e3545",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
